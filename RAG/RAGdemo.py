import os
import shutil

import lancedb
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import TextLoader
from langchain_community.embeddings import BaichuanTextEmbeddings
from langchain_community.vectorstores import LanceDB
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_text_splitters import RecursiveCharacterTextSplitter

# è®¾ç½® API Key
os.environ['BAICHUAN_API_KEY'] = 'sk-c3cb1ff363cd14e257a673bc3d9e0d16'

print("ğŸ“š å¼€å§‹æ„å»º RAG ç³»ç»Ÿ...")

# åŠ è½½æ–‡æ¡£
print("ğŸ“– åŠ è½½æ–‡æ¡£...")
loader = TextLoader(file_path="test.txt", encoding='utf-8')
documents = loader.load()
print(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")

# æ–‡æœ¬åˆ†å‰²
print("âœ‚ï¸ åˆ†å‰²æ–‡æ¡£...")
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=200,  # å¢åŠ å—å¤§å°
    chunk_overlap=50,  # å¢åŠ é‡å 
    length_function=len,
    is_separator_regex=False,
    separators=[
        "\n\n",
        "\n",
        "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?",
        ",", "ï¼Œ", ";", "ï¼›",
        "ã€", " ",
        ""
    ]
)
docs = text_splitter.split_documents(documents)
print(f"âœ… åˆ†å‰²æˆ {len(docs)} ä¸ªæ–‡æ¡£å—")

# ä½¿ç”¨ç™¾å·åµŒå…¥æ¨¡å‹ï¼ˆæ›´ç¨³å®šï¼‰
print("ğŸ§  åˆå§‹åŒ–åµŒå…¥æ¨¡å‹...")
embeddings = BaichuanTextEmbeddings()

# æ¸…ç†æ—§çš„æ•°æ®åº“
db_path = os.path.join(os.getcwd(), "lanceDB")
if os.path.exists(db_path):
    print("ğŸ—‘ï¸ æ¸…ç†æ—§çš„æ•°æ®åº“...")
    shutil.rmtree(db_path)

# è¿æ¥å‘é‡æ•°æ®åº“
print("ğŸ’¾ åˆ›å»ºå‘é‡æ•°æ®åº“...")
db = lancedb.connect(db_path)

# åˆ›å»ºå‘é‡å­˜å‚¨
print("ğŸ”„ ç”Ÿæˆå‘é‡åµŒå…¥å¹¶å­˜å‚¨...")
vectorStore = LanceDB.from_documents(
    docs,
    embeddings,
    connection=db,
    table_name="my_vectors"
)
print("âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼")

# ==================== RAG æŸ¥è¯¢éƒ¨åˆ† ====================
print("\nğŸ” å¼€å§‹ RAG æŸ¥è¯¢æµ‹è¯•...")

# æµ‹è¯•æŸ¥è¯¢
query = ('ç¾å›½é¦–æ¬¡ç”³è¯·å¤±ä¸šæ•‘æµäººæ•°å¢åŠ äº†å¤šå°‘ï¼Ÿä¸Šä¸€æ¬¡æ–°é«˜æ˜¯ä»€ä¹ˆæ—¶å€™')
print(f"ğŸ“ æŸ¥è¯¢é—®é¢˜: {query}")

# æµ‹è¯•å‘é‡ç›¸ä¼¼æ€§æœç´¢
print("ğŸ” æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢...")
docs_and_scores = vectorStore.similarity_search_with_score(query, k=3)
print(f"âœ… æ‰¾åˆ° {len(docs_and_scores)} ä¸ªç›¸å…³æ–‡æ¡£")

# æ˜¾ç¤ºæ£€ç´¢åˆ°çš„æ–‡æ¡£
for i, (doc, score) in enumerate(docs_and_scores):
    print(f"\nğŸ“„ æ–‡æ¡£ {i+1} (ç›¸ä¼¼åº¦: {score:.4f}):")
    print(f"å†…å®¹: {doc.page_content[:100]}...")

# åˆ›å»ºæ£€ç´¢å™¨
print("\nğŸ”§ åˆ›å»º RAG é“¾...")
retriever = vectorStore.as_retriever(search_kwargs={"k": 3})

# å®šä¹‰æç¤ºè¯æ¨¡æ¿
template = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©ç†ã€‚æ ¹æ®ä»¥ä¸‹æä¾›çš„æ–‡æ¡£æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœä½ ä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯´ä½ ä¸çŸ¥é“ï¼Œè€Œä¸æ˜¯ç¼–é€ ç­”æ¡ˆã€‚

æ–‡æ¡£å†…å®¹:
{context}

é—®é¢˜: {question}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å›ç­”:"""

prompt = ChatPromptTemplate.from_template(template)

# åˆ›å»ºæ¨¡å‹
model = ChatOpenAI(
    model='glm-4-0520',
    temperature=0.6,  # ä¿®æ­£ä¸ºæ•°å­—ç±»å‹
    api_key='06ca1c42545b44b2a3bb85531c7024a8.bDEKFcPHfhhYvm1Q',
    base_url='https://open.bigmodel.cn/api/paas/v4',
)

output_parser = StrOutputParser()

# æ„å»º RAG é“¾
# å¹¶è¡Œå¤„ç†ï¼šåŒæ—¶è·å–æ£€ç´¢ç»“æœå’Œç”¨æˆ·é—®é¢˜
rag_chain = (
    RunnableParallel({
        "context": retriever,
        "question": RunnablePassthrough()
    })
    | prompt
    | model
    | output_parser
)

# æ‰§è¡ŒæŸ¥è¯¢
print("\nğŸš€ æ‰§è¡Œ RAG æŸ¥è¯¢...")
try:
    response = rag_chain.invoke(query)
    print(f"\nâœ… RAG å›ç­”:\n{response}")
except Exception as e:
    print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

print("\nğŸ‰ RAG ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
